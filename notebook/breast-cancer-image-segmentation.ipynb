{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# pip install tensorflow","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.095688Z","iopub.execute_input":"2023-09-02T15:27:33.096135Z","iopub.status.idle":"2023-09-02T15:27:33.100199Z","shell.execute_reply.started":"2023-09-02T15:27:33.096100Z","shell.execute_reply":"2023-09-02T15:27:33.099191Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose\nimport random\nimport glob\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.124367Z","iopub.execute_input":"2023-09-02T15:27:33.125040Z","iopub.status.idle":"2023-09-02T15:27:33.133039Z","shell.execute_reply.started":"2023-09-02T15:27:33.125005Z","shell.execute_reply":"2023-09-02T15:27:33.131786Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.134915Z","iopub.execute_input":"2023-09-02T15:27:33.135493Z","iopub.status.idle":"2023-09-02T15:27:33.145963Z","shell.execute_reply.started":"2023-09-02T15:27:33.135456Z","shell.execute_reply":"2023-09-02T15:27:33.144821Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"2.11.0\n","output_type":"stream"}]},{"cell_type":"code","source":"masks = glob.glob(\"/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/*/*_mask.png\")","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.151251Z","iopub.execute_input":"2023-09-02T15:27:33.152026Z","iopub.status.idle":"2023-09-02T15:27:33.163512Z","shell.execute_reply.started":"2023-09-02T15:27:33.151986Z","shell.execute_reply":"2023-09-02T15:27:33.162398Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"masks[:4]","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.165470Z","iopub.execute_input":"2023-09-02T15:27:33.165913Z","iopub.status.idle":"2023-09-02T15:27:33.172430Z","shell.execute_reply.started":"2023-09-02T15:27:33.165877Z","shell.execute_reply":"2023-09-02T15:27:33.171448Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (166)_mask.png',\n '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (290)_mask.png',\n '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (430)_mask.png',\n '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (89)_mask.png']"},"metadata":{}}]},{"cell_type":"code","source":"images = [mask_images.replace(\"_mask\", \"\") for mask_images in masks]","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.233635Z","iopub.execute_input":"2023-09-02T15:27:33.234793Z","iopub.status.idle":"2023-09-02T15:27:33.240765Z","shell.execute_reply.started":"2023-09-02T15:27:33.234745Z","shell.execute_reply":"2023-09-02T15:27:33.239743Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"images[:4]","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.243006Z","iopub.execute_input":"2023-09-02T15:27:33.243882Z","iopub.status.idle":"2023-09-02T15:27:33.253382Z","shell.execute_reply.started":"2023-09-02T15:27:33.243697Z","shell.execute_reply":"2023-09-02T15:27:33.252302Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"['/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (166).png',\n '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (290).png',\n '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (430).png',\n '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (89).png']"},"metadata":{}}]},{"cell_type":"code","source":"series = list(zip(images, masks))","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.254961Z","iopub.execute_input":"2023-09-02T15:27:33.255941Z","iopub.status.idle":"2023-09-02T15:27:33.263326Z","shell.execute_reply.started":"2023-09-02T15:27:33.255907Z","shell.execute_reply":"2023-09-02T15:27:33.262356Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"series[:4]","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.266533Z","iopub.execute_input":"2023-09-02T15:27:33.267338Z","iopub.status.idle":"2023-09-02T15:27:33.275057Z","shell.execute_reply.started":"2023-09-02T15:27:33.267302Z","shell.execute_reply":"2023-09-02T15:27:33.273990Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"[('/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (166).png',\n  '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (166)_mask.png'),\n ('/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (290).png',\n  '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (290)_mask.png'),\n ('/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (430).png',\n  '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (430)_mask.png'),\n ('/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (89).png',\n  '/kaggle/input/breast-ultrasound-images-dataset/Dataset_BUSI_with_GT/benign/benign (89)_mask.png')]"},"metadata":{}}]},{"cell_type":"code","source":"dataset = pd.DataFrame(series, columns=['image_path', 'mask_path'])","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.278304Z","iopub.execute_input":"2023-09-02T15:27:33.278875Z","iopub.status.idle":"2023-09-02T15:27:33.285299Z","shell.execute_reply.started":"2023-09-02T15:27:33.278821Z","shell.execute_reply":"2023-09-02T15:27:33.284327Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.286651Z","iopub.execute_input":"2023-09-02T15:27:33.287469Z","iopub.status.idle":"2023-09-02T15:27:33.302509Z","shell.execute_reply.started":"2023-09-02T15:27:33.287436Z","shell.execute_reply":"2023-09-02T15:27:33.301296Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"                                            image_path  \\\n0    /kaggle/input/breast-ultrasound-images-dataset...   \n1    /kaggle/input/breast-ultrasound-images-dataset...   \n2    /kaggle/input/breast-ultrasound-images-dataset...   \n3    /kaggle/input/breast-ultrasound-images-dataset...   \n4    /kaggle/input/breast-ultrasound-images-dataset...   \n..                                                 ...   \n775  /kaggle/input/breast-ultrasound-images-dataset...   \n776  /kaggle/input/breast-ultrasound-images-dataset...   \n777  /kaggle/input/breast-ultrasound-images-dataset...   \n778  /kaggle/input/breast-ultrasound-images-dataset...   \n779  /kaggle/input/breast-ultrasound-images-dataset...   \n\n                                             mask_path  \n0    /kaggle/input/breast-ultrasound-images-dataset...  \n1    /kaggle/input/breast-ultrasound-images-dataset...  \n2    /kaggle/input/breast-ultrasound-images-dataset...  \n3    /kaggle/input/breast-ultrasound-images-dataset...  \n4    /kaggle/input/breast-ultrasound-images-dataset...  \n..                                                 ...  \n775  /kaggle/input/breast-ultrasound-images-dataset...  \n776  /kaggle/input/breast-ultrasound-images-dataset...  \n777  /kaggle/input/breast-ultrasound-images-dataset...  \n778  /kaggle/input/breast-ultrasound-images-dataset...  \n779  /kaggle/input/breast-ultrasound-images-dataset...  \n\n[780 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>mask_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>775</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>776</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>777</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>778</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n    <tr>\n      <th>779</th>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n      <td>/kaggle/input/breast-ultrasound-images-dataset...</td>\n    </tr>\n  </tbody>\n</table>\n<p>780 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train, test= train_test_split(dataset, test_size=0.25)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.304071Z","iopub.execute_input":"2023-09-02T15:27:33.305053Z","iopub.status.idle":"2023-09-02T15:27:33.312721Z","shell.execute_reply.started":"2023-09-02T15:27:33.305014Z","shell.execute_reply":"2023-09-02T15:27:33.311666Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n\ntrain_image_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n    dataframe=train, \n    directory=None,\n    x_col='image_path',\n    y_col=None,\n    target_size=(256, 256),\n    batch_size=8,\n    shuffle=True,\n    class_mode=None\n)\n\ntrain_mask_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n    dataframe=train,\n    directory=None,\n    x_col='mask_path',\n    y_col=None,\n    target_size=(256, 256), \n    batch_size=8,\n    shuffle=True,\n    class_mode=None\n)\n\nval_image_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n    dataframe=test,\n    directory=None, \n    x_col='image_path',\n    y_col=None,\n    target_size=(256, 256),\n    batch_size=8,\n    shuffle=False,\n    class_mode=None\n)\n\nval_mask_gen = ImageDataGenerator(rescale=1./255).flow_from_dataframe(\n    dataframe=test,\n    directory=None,\n    x_col='mask_path',\n    y_col=None,\n    target_size=(256, 256),\n    batch_size=8,\n    shuffle=False,\n    class_mode=None\n)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.356003Z","iopub.execute_input":"2023-09-02T15:27:33.356409Z","iopub.status.idle":"2023-09-02T15:27:33.733021Z","shell.execute_reply.started":"2023-09-02T15:27:33.356376Z","shell.execute_reply":"2023-09-02T15:27:33.732064Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Found 585 validated image filenames.\nFound 585 validated image filenames.\nFound 195 validated image filenames.\nFound 195 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate\nfrom tensorflow.keras.models import Model\n\nclass UNet:\n    def __init__(self, input_shape=(256, 256, 3), num_classes=1):\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.model = self.build_model()\n\n    def conv_block(self, inputs, filters, kernel_size=3, activation='relu', padding='same'):\n        conv = Conv2D(filters, kernel_size, activation=activation, padding=padding)(inputs)\n        conv = Conv2D(filters, kernel_size, activation=activation, padding=padding)(conv)\n        return conv\n\n    def build_model(self):\n        inputs = Input(self.input_shape)\n\n        # Encoder\n        conv1 = self.conv_block(inputs, 64)\n        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n        conv2 = self.conv_block(pool1, 128)\n        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n        conv3 = self.conv_block(pool2, 256)\n        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n        conv4 = self.conv_block(pool3, 512)\n        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n\n        conv5 = self.conv_block(pool4, 1024)\n\n        # Decoder\n        up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n        concat6 = concatenate([conv4, up6], axis=3)\n        conv6 = self.conv_block(concat6, 512)\n\n        up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n        concat7 = concatenate([conv3, up7], axis=3)\n        conv7 = self.conv_block(concat7, 256)\n\n        up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n        concat8 = concatenate([conv2, up8], axis=3)\n        conv8 = self.conv_block(concat8, 128)\n\n        up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n        concat9 = concatenate([conv1, up9], axis=3)\n        conv9 = self.conv_block(concat9, 64)\n\n        # Output\n        outputs = Conv2D(self.num_classes, (1, 1), activation='sigmoid')(conv9)\n\n        model = Model(inputs=inputs, outputs=outputs)\n        return model\n","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:33.735140Z","iopub.execute_input":"2023-09-02T15:27:33.735783Z","iopub.status.idle":"2023-09-02T15:27:33.751393Z","shell.execute_reply.started":"2023-09-02T15:27:33.735744Z","shell.execute_reply":"2023-09-02T15:27:33.750084Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"model = UNet()\nmodel.build_model()\n\nmodel.model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n\n# tf.keras.utils.plot_model(model.model, './model_plot.png', show_shapes = True)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:39.781140Z","iopub.execute_input":"2023-09-02T15:27:39.781508Z","iopub.status.idle":"2023-09-02T15:27:40.318547Z","shell.execute_reply.started":"2023-09-02T15:27:39.781477Z","shell.execute_reply":"2023-09-02T15:27:40.317581Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\ntrain_gen = zip(train_image_gen, train_mask_gen)\nval_gen = zip(val_image_gen, val_mask_gen)\n\nnum_samples = len(train_image_gen)\nsteps_per_epoch = num_samples // 8\n\nhistory = model.model.fit(train_gen, \n                    validation_data=val_gen,\n                    epochs=10,\n                    steps_per_epoch=steps_per_epoch,      \n                    callbacks=[early_stopping], \n                    verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:41.303502Z","iopub.execute_input":"2023-09-02T15:27:41.304073Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch 1/10\n9/9 [==============================] - ETA: 0s - loss: 0.6780 - accuracy: 0.7293","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 4))\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-02T15:27:34.748627Z","iopub.status.idle":"2023-09-02T15:27:34.749349Z","shell.execute_reply.started":"2023-09-02T15:27:34.749097Z","shell.execute_reply":"2023-09-02T15:27:34.749121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}